# 适用于树莓派的AI瞌睡检测系统UI方案

## 背景

当前项目在树莓派上运行 `DrowsinessDetector.py` 时，基于 PyQt5 的用户界面遇到了 Qt 平台插件 (xcb) 加载问题。这在嵌入式设备上是常见挑战，主要原因包括：

1.  **复杂的依赖关系**：桌面GUI工具包（如PyQt5）通常依赖众多系统库，在资源受限的树莓派上配置和编译可能很困难。
2.  **资源消耗**：这类工具包可能对CPU和内存有较高要求。
3.  **平台兼容性**：特定于X11的插件（如xcb）可能与树莓派的显示服务器或配置不完全兼容，尤其是在 headless 模式或特定桌面环境下。

本项目核心是实时AI算法检测，UI主要用于状态显示和报警。因此，选择一个轻量级、易于部署且在树莓派上表现良好的UI方案至关重要。同时，考虑到未来可能的触屏交互需求，方案应具备良好的触屏支持。

## 推荐UI方案

### 方案一：Web界面 (Flask/FastAPI + HTML/CSS/JavaScript) - （强烈推荐）

这是在嵌入式设备（如树莓派）上部署带有用户界面的AI应用的首选方案。

**架构：**

1.  **后端 (Python)**：
    *   使用轻量级的Python Web框架（如 **Flask** 或 **FastAPI**）来包装现有的 `DrowsinessDetector.py` 检测逻辑。
    *   后端将负责：
        *   启动和管理摄像头。
        *   运行YOLOv8模型进行眼睛和打哈欠检测。
        *   处理MediaPipe的面部标志点。
        *   根据检测结果判断瞌睡状态。
        *   通过API接口向上层Web界面提供数据。
2.  **前端 (HTML/CSS/JS)**：
    *   一个简单的HTML页面，通过CSS进行样式设计，使用JavaScript与后端API交互。
    *   前端将负责：
        *   实时显示当前的瞌睡状态（例如："清醒"、"轻度疲劳"、"瞌睡警告"）。
        *   显示报警信息。
        *   （可选）显示来自摄像头的处理后视频流或关键帧图像。
        *   （可选）提供简单的控制按钮（如开始/停止检测）。
3.  **通信方式**：
    *   **REST API**：用于前端获取一次性数据或发送命令。
    *   **WebSockets**：用于后端向前端实时推送状态更新和报警信息，这是实现低延迟实时显示的关键。
    *   **MJPEG-streamer 或类似技术**：如果需要在Web界面上实时显示视频流，可以考虑使用此技术，或者后端定期将处理后的图像帧通过WebSockets发送（注意带宽和性能）。

**实施步骤概要：**

1.  **重构核心AI检测逻辑 (创建 `ai_logic.py`)**：
    *   创建一个新的Python文件，例如 `ai_logic.py`。
    *   将 `DrowsinessDetector.py` 中与AI检测相关的功能（摄像头帧处理、MediaPipe面部标志点检测、YOLOv8模型推理、瞌睡状态判断逻辑）迁移到 `ai_logic.py` 中。
    *   设计一个主类（如 `AIDrowsinessProcessor`）或一组函数在 `ai_logic.py` 中，该模块将不依赖任何GUI库（如PyQt5）。
    *   `AIDrowsinessProcessor` 类应包含以下主要方法：
        *   `__init__(self, yolo_eye_model_path, yolo_yawn_model_path, camera_index=0)`: 初始化摄像头、加载YOLO模型、初始化MediaPipe。
        *   `process_frame(self, frame)`: 接收一个原始摄像头帧，执行面部检测、ROI提取、眼睛状态预测、打哈欠预测，并更新内部状态（如眨眼计数、微睡眠时间、打哈欠计数和持续时间）。返回一个包含当前所有状态信息的字典。
        *   `get_current_status(self)`: 返回包含最新检测状态和统计数据的字典。
        *   `get_processed_frame(self)`: （可选）返回带有绘制信息的处理后帧，用于在Web界面显示。
    *   移除原 `DrowsinessDetector.py` 中的PyQt5界面代码、线程管理（这部分将由Web后端处理或调整）、以及特定于Windows的 `winsound` 报警。

2.  **创建Flask/FastAPI后端应用 (例如 `app.py`)**：
    *   初始化 `AIDrowsinessProcessor` 的实例。
    *   实现HTTP API端点：
        *   `/status` (GET): 调用 `AIDrowsinessProcessor.get_current_status()` 返回JSON格式的当前检测状态和统计数据。
        *   `/start_detection` (POST): （如果需要手动控制）触发开始检测的逻辑。
        *   `/stop_detection` (POST): （如果需要手动控制）触发停止检测的逻辑。
    *   **视频流 (可选但推荐)**:
        *   实现一个视频流端点 (例如 `/video_feed`)。这可以通过多种方式完成：
            *   **MJPEG流**: 后端在一个循环中从 `AIDrowsinessProcessor` 获取处理后的帧，编码为JPEG，并作为 `multipart/x-mixed-replace; boundary=frame` 响应流式传输。
            *   **WebSockets**: 定期将处理后的帧（可能进行压缩或降采样）通过WebSockets发送给前端。
    *   **实时状态更新 (使用WebSockets)**：
        *   设置一个WebSockets端点 (例如 `/ws/status`)。
        *   后端在独立的线程/任务中持续运行 `AIDrowsinessProcessor.process_frame()`，并将每次更新的状态通过WebSockets推送给所有连接的前端客户端。
    *   **报警处理**: 当检测到瞌睡事件时，后端可以通过WebSockets向前端发送报警信号，前端接收到信号后可以播放声音或显示视觉警报。

3.  **创建前端页面 (例如 `index.html`, `style.css`, `script.js`)**：
    *   **HTML (`index.html`)**:
        *   设计页面布局，包括显示摄像头视频流的区域（如果实现）、显示状态信息（眨眼次数、微睡眠、哈欠等）的区域，以及报警提示区域。
    *   **CSS (`style.css`)**:
        *   美化界面，确保信息清晰易读。
    *   **JavaScript (`script.js`)**:
        *   使用 `fetch` API 或 `XMLHttpRequest` 从 `/status` 端点获取初始状态。
        *   建立到 `/ws/status` 的WebSocket连接，接收后端推送的实时状态更新，并动态更新HTML页面内容。
        *   如果实现了视频流：
            *   对于MJPEG流，可以直接将 `<img>` 标签的 `src` 指向 `/video_feed`。
            *   对于WebSockets视频，需要接收图像数据并将其绘制到 `<canvas>` 元素或更新 `<img>` 标签。
        *   处理从后端接收到的报警信号（例如，通过 `Audio` 对象播放预加载的声音文件，或改变页面元素的样式以示警报）。

4.  **配置树莓派运行环境**：
    *   安装Python、Flask/FastAPI、OpenCV、YOLOvPytorch (Ultralytics)、MediaPipe及其所有依赖。
    *   确保摄像头在树莓派上被正确识别和访问。
    *   配置Web服务器（如Gunicorn或Uvicorn，如果使用FastAPI）以便在生产环境中运行Python后端应用。
    *   设置Python后端应用和Chromium浏览器（以Kiosk模式指向 `http://localhost:PORT`）开机自启动。

**优点：**

*   **轻量级**：相比完整的桌面GUI库，Web服务器和前端页面对资源的消耗通常更低。
*   **部署简单**：Python Web框架和静态前端文件在树莓派上部署相对容易，依赖问题少。
*   **兼容性好**：现代浏览器对HTML5/CSS3/JS的支持非常好，跨平台兼容性强。
*   **优秀的触屏支持**：Web技术原生支持触摸事件。
*   **解耦**：UI和核心检测逻辑分离，便于独立开发和维护。
*   **远程访问**：天然支持通过网络在其他设备上查看UI（如果需要）。
*   **避免Qt插件问题**：完全绕开了PyQt5及其复杂的插件依赖。

### 方案二：Kivy

Kivy是另一个值得考虑的Python UI框架，特别为新颖的用户界面和多点触控应用而设计。

**优点：**

*   **原生触屏支持**：Kivy从设计之初就考虑了触摸和手势。
*   **GPU加速**：可以利用GPU进行渲染，界面流畅度可能较好。
*   **跨平台**：虽然主要目标是树莓派，但代码理论上也可在其他平台运行。
*   **统一语言**：UI和应用逻辑都使用Python（以及可选的Kv语言）。

**缺点/挑战：**

*   **学习曲线**：如果团队不熟悉Kivy及其Kv设计语言，需要学习成本。
*   **依赖与安装**：Kivy也有其自身的依赖，虽然比PyQt5通常要好管理一些，但在树莓派上仍需确保安装顺利。官方有提供针对树莓派的安装指南。
*   **与现有代码集成**：需要将 `DrowsinessDetector.py` 的事件循环与Kivy的事件循环相结合。

**实施步骤概要：**

1.  **安装Kivy**：根据Kivy官方文档在树莓派上安装Kivy。
2.  **UI设计**：使用Kivy的组件（Widgets）和布局（Layouts）重新设计界面。
3.  **逻辑集成**：将 `DrowsinessDetector.py` 中的检测逻辑与Kivy应用的生命周期和事件处理结合起来。例如，在一个Kivy的时钟事件（`Clock.schedule_interval`）中获取摄像头帧并进行处理，然后更新UI元素。

## 结论与建议

对于当前项目在树莓派上的部署，**强烈建议采用方案一：Web界面**。它能有效解决当前遇到的Qt平台插件问题，提供良好的触屏支持，且对系统资源要求相对较低，部署和维护也更为灵活。

Kivy作为备选方案，如果团队对Kivy有一定经验，或者对界面的"原生感"有更高要求，且愿意投入时间解决其可能的依赖和集成问题，也是一个可行的选择。

无论选择哪种方案，核心的AI检测算法 `DrowsinessDetector.py` 的逻辑部分是可以复用的，主要工作在于构建新的UI交互层。

## 新版Web界面使用说明

重构后的项目采用Flask作为后端，提供Web界面进行实时疲劳检测的监控。

### 1. 环境准备与依赖安装

确保您的Python环境已正确设置。项目根目录下的 `requirements.txt` 文件列出了所有必要的Python依赖。请在项目根目录下运行以下命令安装它们：

```bash
pip install -r requirements.txt
```

请确保您的摄像头已连接并被系统正确识别。如果使用的是预训练模型，请确保 `runs/detecteye/train/weights/best.pt` 和 `runs/detectyawn/train/weights/best.pt` 模型文件存在于项目根目录下的相应路径。如果路径不同，请修改 `src/ai_logic.py` 和 `app.py` 中的模型路径配置。

### 2. 启动后端服务

在项目根目录 (`01_driver/real-time-drowsy-driving-detection/`)下，运行 `app.py` 来启动Flask后端服务：

```bash
python app.py
```

服务启动后，您应该会在终端看到类似以下的输出信息，表明服务正在运行，通常监听在 `http://0.0.0.0:5000/`：

```
Starting Flask-SocketIO server...
Initializing AIDrowsinessProcessor...
AIDrowsinessProcessor initialized successfully.
 * Serving Flask app 'app'
 * Debug mode: off
WARNING: This is a development server. Do not use it in a production deployment.
   Use a production WSGI server instead.
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://[your-local-ip]:5000
Press CTRL+C to quit
```

### 3. 访问Web用户界面

打开您的网页浏览器（如Chrome, Firefox等），访问后端服务提供的地址，默认为：

`http://localhost:5000`

或者，如果您在局域网内的其他设备上访问，可以使用运行 `app.py` 的计算机的IP地址，例如 `http://192.168.1.10:5000` (请替换为实际IP地址)。

### 4. Web界面功能

Web界面包含以下主要部分：

*   **AI Drowsiness Detector (标题)**: 应用的名称。
*   **Live Feed (实时视频流)**:
    *   显示来自摄像头的实时视频，并叠加AI检测的边界框（如面部、眼睛、嘴巴区域）和关键点。
*   **Current Status (当前状态)**:
    *   **Overall Alert**: 显示当前的总体警报状态（例如 "Awake", "Prolonged Microsleep Detected!", "Prolonged Yawn Detected!"）。
    *   **Blinks**: 眨眼次数的累计。
    *   **Microsleeps**: 微睡眠的累计持续时间（秒）。
    *   **Yawns**: 打哈欠次数的累计。
    *   **Yawn Duration**: 当前或上一个哈欠的持续时间（秒）。
    *   **Left Eye**: 左眼状态 ("Open Eye" / "Close Eye")。
    *   **Right Eye**: 右眼状态 ("Open Eye" / "Close Eye")。
    *   **Yawn State**: 哈欠状态 ("Yawn" / "No Yawn")。
*   **Controls (控制按钮)**:
    *   **Start Detection**: 点击此按钮会通过API请求后端开始AI检测处理，并启动/刷新视频流。
    *   **Stop Detection**: 点击此按钮会通过API请求后端停止AI检测处理。视频流可能会显示最后一帧或停止更新。
*   **Event Log (事件日志)**:
    *   显示WebSocket连接状态、服务器消息以及重要的警报事件，并附带时间戳。

### 5. 停止服务

在运行 `app.py` 的终端中，按下 `CTRL+C` 来停止Flask后端服务。

### 注意事项

*   **模型路径**：如前所述，`ai_logic.py` 和 `app.py` 中的YOLO模型路径是硬编码的。如果您的模型文件位于不同位置，请务必更新这些路径。
*   **摄像头索引**：默认使用索引为 `0` 的摄像头。如果您有多个摄像头或需要指定特定摄像头，可以在 `ai_logic.py` 中 `AIDrowsinessProcessor` 类的初始化部分修改 `camera_index` 参数，或者在 `app.py` 的 `initialize_processor` 函数中修改传递给 `AIDrowsinessProcessor` 的 `camera_index`。
*   **性能**：在资源受限的设备（如树莓派）上运行时，请关注CPU和内存使用情况。如果视频流卡顿或检测延迟过高，可能需要优化模型、降低摄像头分辨率或帧率等。
*   **声音警报**：当前版本的前端 `script.js` 中预留了播放声音警报的注释代码。如需启用，您需要提供声音文件，并在JavaScript中取消注释并正确配置声音文件路径，同时注意浏览器对自动播放音频的限制。
