# 开发日志 - 疲劳驾驶检测项目 TFLite 迁移与调试

本文档记录了将 YOLOv8 PyTorch 模型迁移到 TFLite 格式，并在树莓派目标设备上进行集成和调试的主要过程、遇到的问题及解决方案。

## 阶段一：模型转换与初步集成

**目标**:
*   将训练好的眼睛检测和打哈欠检测 YOLOv8 PyTorch 模型 (`.pt`) 转换为 TFLite 格式 (`.tflite`)，包括 FP16 和 INT8 量化版本。
*   更新 `适配树莓派.md` 文档，记录 TFLite 转换和集成步骤。
*   修改 `src/ai_logic.py` 以使用 TFLite Runtime 进行推理。
*   修改 `app.py` 以支持加载不同的 TFLite 模型权重，并方便测试。

**主要变更**:
1.  **文档更新 (`适配树莓派.md`)**:
    *   添加了关于 YOLOv8 模型导出为 TFLite 的说明，指出模型已转换并存放于 `model/tflite/`。
    *   详细描述了如何在 `src/ai_logic.py` 中集成 TFLite 模型，包括依赖安装、模型加载、预处理、推理执行和后处理。
    *   增加了测试不同 TFLite 模型权重（INT8, FP16,不同输入尺寸）的说明。

2.  **AI 推理逻辑修改 (`src/ai_logic.py`)**:
    *   移除了 `ultralytics` YOLO 对象的直接使用。
    *   引入 `tflite_runtime.interpreter.Interpreter` (或 `tensorflow.lite.python.interpreter.Interpreter` 作为备选) 来加载 `.tflite` 模型。
    *   在 `AIDrowsinessProcessor` 的 `__init__` 方法中初始化 TFLite解释器，获取输入输出张量的详细信息。
    *   实现了针对 TFLite 模型的图像预处理逻辑：调整大小、归一化（例如，FP16 模型通常需要 `float32` 输入，范围 `0-1`；INT8 模型可能需要 `uint8` 输入并根据其量化参数进行调整）。
    *   重写了 `_parse_tflite_output` 方法来解析 TFLite 模型的原始输出张量。YOLOv8 导出的 TFLite 模型输出格式（通常为 `[1, num_boxes, 5 + num_classes]` 或其转置形式，如 `[1, 6, 2100]` 其中 6 代表 `x,y,w,h,conf,class_id`）需要特别处理。

3.  **主应用逻辑修改 (`app.py`)**:
    *   添加了 `argparse` 模块，允许通过命令行参数指定要加载的眼睛和打哈欠 TFLite 模型路径。
    *   引入了 `MODEL_CONFIGURATIONS` 字典，预定义了多组模型配置（如 `int8_320`, `fp16_640` 等），方便在代码中通过 `DEFAULT_MODEL_CONFIG_KEY` 切换默认模型。命令行参数可以覆盖这些默认设置。
    *   修改 `initialize_resources` 函数，使其根据提供的路径加载 TFLite 模型到 `AIDrowsinessProcessor`。

4.  **依赖更新 (`requirements.txt`)**:
    *   最初尝试添加 `tensorflow-lite>=2.6.0` 以支持 TFLite Runtime。

## 阶段二：调试浏览器无画面问题

在完成初步集成后，遇到的核心问题是在浏览器中无法显示视频流（先是破损图片图标，后是持续黑屏）。

**调试过程与解决方案**:

1.  **TFLite Runtime 安装问题 (树莓派环境)**:
    *   **问题**: 在树莓派上执行 `pip install -r requirements.txt` 时，`tensorflow-lite` 包找不到匹配的分发版本 (`ERROR: No matching distribution found for tensorflow-lite`)。
    *   **诊断**: 通过网络搜索确认 `tensorflow-lite` 在 PyPI 上可能没有为所有 ARM 架构提供预编译包，而 `tflite-runtime` 是更通用的选择。
    *   **解决**:
        *   将 `requirements.txt` 中的 `tensorflow-lite>=2.6.0` 修改为 `tflite-runtime`。
        *   指导用户更新 pip (`python3 -m pip install --upgrade pip`) 并重新安装依赖。此步骤最终成功安装了 TFLite Runtime。
        *   同步更新了 `适配树莓派.md` 文档中的依赖安装说明。

2.  **视频流生成逻辑错误 (`app.py` - `video_stream_generator`)**:
    *   **问题**: 即便 TFLite Runtime 安装成功，浏览器依然黑屏。
    *   **诊断**: 开始怀疑 `video_stream_generator` 函数内部的MJPEG帧编码或传输存在问题。通过添加日志进行追踪。
    *   **发现与解决 1 (`NameError: name 'ret' is not defined`)**:
        *   日志（通过逐步添加 `print` 语句）定位到 `cv2.imencode('.jpg', ...)` 的返回值 `ret` 在被条件判断前未被赋值。原因是 `imencode` 调用位置错误。
        *   **修复**: 将 `ret, encoded_image = cv2.imencode('.jpg', current_frame_to_display)` 移至 `current_frame_to_display` 被（可能被 `draw_overlays` 修改）确定之后，且在 `if not ret:` 判断之前。

3.  **线程间数据流与状态同步问题 (`app.py`)**:
    *   **问题**: 修复 `ret` 变量问题后，依旧黑屏。终端日志显示 `[CAMERA_THREAD] CRITICAL ERROR in loop: name 'APP_STATE' is not defined`。
    *   **诊断**: `camera_thread_function` 尝试通过一个名为 `APP_STATE` 的对象访问锁 (`raw_frame_lock`) 和队列 (`frame_queue_for_ai`)，但 `APP_STATE` 对象并未在全局正确定义或初始化。实际上，这些锁和队列是直接在全局作用域定义的。
    *   **修复**:
        *   修改 `camera_thread_function`（以及后来看来也影响到 `ai_processing_thread_function` 和 `video_stream_generator` 的类似情况），使其直接使用全局定义的 `raw_frame_lock`, `frame_queue_for_ai`, `stats_lock` 等。
        *   修正了这些线程函数顶部的 `global` 声明，确保所有实际使用的全局变量（如 `stop_event`, `APP_ARGS` 以及直接使用的锁和队列名）都被正确声明。

4.  **TFLite 模型输出解析与 AI 逻辑 (`src/ai_logic.py`)**:
    *   **问题**: 修复 `APP_STATE` 问题后，摄像头线程和 AI 线程开始打印日志，表明它们在运行，但浏览器依然黑屏，且 AI 模型似乎未正确检测目标。
    *   **诊断**: 在 `src/ai_logic.py` 的 `_parse_tflite_output` 函数中加入了详细的调试打印，以观察模型原始输出和解析过程。
        *   日志显示模型输出的 `shape` 为 `(1, 6, 2100)`。代码中存在一个基于输出第二维和第三维大小关系的转置逻辑，将其转换为 `(1, 2100, 6)`，这符合 YOLO 输出的常见格式（NMS 可能已在模型内部或导出时集成）。
        *   初步测试 INT8 模型时，注意到其输入 `dtype` 和 `quantization` 参数，确保预处理符合要求（FP16 模型使用 `float32` 输入，INT8 模型通常使用 `uint8`）。大部分调试后续集中在使用 FP16 模型上。
        *   日志显示 `_parse_tflite_output` 大部分时间返回 `BestClassID: -1, MaxConfidence: -1.0`，表明未达到置信度阈值（0.3）或无检测。但偶尔会有成功检测的记录，说明解析逻辑通路基本正确。

5.  **`video_stream_generator` 循环执行问题 (`app.py`)**:
    *   **问题**: 尽管摄像头线程捕获帧，AI 线程处理帧，但浏览器依然黑屏。日志分析显示，`video_stream_generator` 函数打印了初始的 "Video stream generator started." 日志后，在检测期间，其内部 `while True:` 循环中添加的详细日志（如获取帧、编码、yield）完全没有出现。仅在停止检测时，才打印退出循环的日志。
    *   **诊断**: 这表明 `video_stream_generator` 在进入其主工作循环或循环的早期阶段就可能阻塞或意外退出了，导致没有帧被 `yield` 给客户端。
    *   **尝试解决**:
        *   在 `video_stream_generator` 函数的更早位置添加日志：函数被调用时、`while True:` 循环初始化参数后、进入 `while True:` 循环的顶部、进入 `try:` 块的顶部。目的是精确定位执行流在何处中断。
        *   使对 `APP_ARGS.display_fps` 的访问更稳健，防止因其未定义或为 `None` 导致错误。

6.  **日志记录持久化**:
    *   **需求**: 为了方便分析和避免因控制台关闭导致日志丢失，需要将所有控制台输出保存到文件。
    *   **实现**:
        *   在 `app.py` 中添加了 `sys`, `os`, `datetime` 导入。
        *   定义了一个 `Tee` 类，用于将输出流（如 `sys.stdout`, `sys.stderr`）同时重定向到原始流和指定文件。
        *   定义了 `setup_file_logging` 函数，用于创建 `logs` 目录（如果不存在），生成带时间戳的日志文件名，并将 `sys.stdout` 和 `sys.stderr` 重定向到 `Tee` 的实例。
        *   在 `if __name__ == '__main__':` 块的开头调用 `setup_file_logging()`。
    *   **结果**: 成功实现了日志输出到 `logs/app_YYYYMMDD_HHMMSS.log` 文件，同时保留控制台输出。

## 当前状态 (截至记录此日志时)

*   应用能够启动，摄像头线程捕获帧，AI 线程处理帧。
*   TFLite 模型（特别是 FP16 版本）能够加载并进行推理，偶尔能检测到目标。
*   **核心问题依然是浏览器端没有视频画面。**
*   最新的调试集中在 `video_stream_generator` 函数，通过添加更早的日志点来确定其内部循环是否按预期执行。等待分析这些新增日志的结果。

## 后续步骤推测
*   分析 `video_stream_generator` 最新的、更详细的日志，找出其未按预期循环和 `yield` 帧的原因。
*   检查是否有任何未捕获的异常或阻塞点在 `video_stream_generator` 的早期逻辑中。
*   确认从 `latest_raw_frame` 获取图像数据是否可靠且持续。
*   一旦视频流问题解决，将进一步测试不同 TFLite 模型的性能和准确性。
